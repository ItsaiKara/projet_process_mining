By group of four, you will study a given dataset (apply all techniques presented during the course) in order to demonstrate what you have learned.

The given data represents varying levels of discrimination per domain. In the following guidelines, you will find the required work to do for each set of data (high, medium, low).

Guidelines:

1. About the log:
    - Traces analysis (which column corresponds to case ID, activity, timestamp) and extra informations (ressources, cost, operator...)
    - Statistics (number of cases/ traces, number of variants, number of cases by variant, average number of activities by cases, min and max number of activities, min-max-average duration, statistics using ressources...)
    - **Are there any outliers? Noise?**
    - Missing part?
    - Reflection about privacy preservation
2. Sampling the log
    - Subset selection (random, more frequent variants...)
    - Discover process models on subset or whole logs using various algorithms
    - Quality criteria for each discovery algorithm
    - Fuzzy Mining analysis
    - Extract factors that cause discrimination and justify (in which processes it was highly visible, i.e. how did you figure it out?)
    - To compare and analyze the different factors among the different data files (are there any common factors? which factors are rarely affecting, which are highly affecting?) 
    - Analyze Business Process
        - Define your objectives, figure out problems or patterns violation...
    - Clustering
        - When clustering, extract the 'profile' of each group which might tell about the factors of discrimination that affected the process and made it different

Deliverables:

    A report in PDF
    A slideshow in PDF
    30' presentation